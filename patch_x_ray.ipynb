{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d2afa56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='patch_camelyon',\n",
      "    full_name='patch_camelyon/2.0.0',\n",
      "    description=\"\"\"\n",
      "    The PatchCamelyon benchmark is a new and challenging image classification\n",
      "    dataset. It consists of 327.680 color images (96 x 96px) extracted from\n",
      "    histopathologic scans of lymph node sections. Each image is annoted with a\n",
      "    binary label indicating presence of metastatic tissue. PCam provides a new\n",
      "    benchmark for machine learning models: bigger than CIFAR10, smaller than\n",
      "    Imagenet, trainable on a single GPU.\n",
      "    \"\"\",\n",
      "    homepage='https://patchcamelyon.grand-challenge.org/',\n",
      "    data_path='/Users/melody.zhao/tensorflow_datasets/patch_camelyon/2.0.0',\n",
      "    download_size=7.48 GiB,\n",
      "    dataset_size=7.06 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'id': Text(shape=(), dtype=tf.string),\n",
      "        'image': Image(shape=(96, 96, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=32768, num_shards=8>,\n",
      "        'train': <SplitInfo num_examples=262144, num_shards=64>,\n",
      "        'validation': <SplitInfo num_examples=32768, num_shards=8>,\n",
      "    },\n",
      "    citation=\"\"\"@misc{b_s_veeling_j_linmans_j_winkens_t_cohen_2018_2546921,\n",
      "      author       = {B. S. Veeling, J. Linmans, J. Winkens, T. Cohen, M. Welling},\n",
      "      title        = {Rotation Equivariant CNNs for Digital Pathology},\n",
      "      month        = sep,\n",
      "      year         = 2018,\n",
      "      doi          = {10.1007/978-3-030-00934-2_24},\n",
      "      url          = {https://doi.org/10.1007/978-3-030-00934-2_24}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "pcam, pcam_info = tfds.load(\"patch_camelyon\", with_info=True)\n",
    "print(pcam_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "43b70ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL.Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67437634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import TensorFlow and relevant Keras classes to setup the model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2709d4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 94, 94, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 92, 92, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 46, 46, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 42, 42, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 19, 19, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 17, 17, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,154,066\n",
      "Trainable params: 1,154,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melody.zhao/.local/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(96,96,3))\n",
    "\n",
    "# Now we define the layers of the convolutional network: three blocks of two convolutional layers and a max-pool layer.\n",
    "x = Conv2D(16, (3, 3), padding='valid', activation='relu')(input_img)\n",
    "x = Conv2D(16, (3, 3), padding='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = Conv2D(32, (3, 3), padding='valid', activation='relu')(x)\n",
    "x = Conv2D(32, (3, 3), padding='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "x = Conv2D(64, (3, 3), padding='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "\n",
    "# Now we flatten the output from a 4D to a 2D tensor to be able to use fully-connected (dense) layers for the final\n",
    "# classification part. Here we also use a bit of dropout for regularization. The last layer uses a softmax to obtain class\n",
    "# likelihoods (i.e. metastasis vs. non-metastasis)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(rate=0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(rate=0.2)(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Now we define the inputs/outputs of the model and setup the optimizer. In this case we use regular stochastic gradient\n",
    "# descent with Nesterov momentum. The loss we use is cross-entropy and we would like to output accuracy as an additional metric.\n",
    "model = Model(inputs=input_img, outputs=predictions)\n",
    "sgd_opt = SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=True)\n",
    "model.compile(optimizer=sgd_opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa4cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_content(img):\n",
    "    max_dim = 512\n",
    "#     img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "    long_dim = max(shape)\n",
    "    scale = max_dim / long_dim\n",
    "\n",
    "    new_shape = tf.cast(shape * scale, tf.int32)\n",
    "\n",
    "    img = tf.image.resize(img, new_shape)\n",
    "    img = img[tf.newaxis, :]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e682222a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {id: (), image: (96, 96, 3), label: ()}, types: {id: tf.string, image: tf.uint8, label: tf.int64}>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcam['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15aa995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6195d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092e120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe02433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d63c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "016c1a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b38cf339",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "eab51128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path_to_img):\n",
    "  max_dim = 512\n",
    "  img = tf.io.read_file(path_to_img)\n",
    "  img = tf.image.decode_image(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "  shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "  long_dim = max(shape)\n",
    "  scale = max_dim / long_dim\n",
    "\n",
    "  new_shape = tf.cast(shape * scale, tf.int32)\n",
    "\n",
    "  img = tf.image.resize(img, new_shape)\n",
    "  img = img[tf.newaxis, :]\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "bfb8242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep the dataset size small PatchCAMELYON is stored as int8 patches. \n",
    "# For network training we need float32 and we want to normalize between 0 and 1. \n",
    "# The function below performs this task.\n",
    "import tensorflow_hub as hub\n",
    "import glob\n",
    "import functools\n",
    "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
    "style_images = glob.glob(\"/Users/melody.zhao/Desktop/CS153-Computer-Vision/style_transfer_imgs/*\")\n",
    "style_image = load_img(style_images[2])\n",
    "\n",
    "def convert_sample(sample):\n",
    "    img, label = sample['image'], sample['label'] \n",
    "    max_dim = 512\n",
    "#     img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "    print(shape)\n",
    "#     long_dim = max(shape)\n",
    "    long_dim = functools.reduce(shape, lambda x, y: x if x > y else y)\n",
    "#     scale = max_dim / long_dim\n",
    "\n",
    "#     new_shape = tf.cast(shape * scale, tf.int32)\n",
    "\n",
    "#     img = tf.image.resize(img, new_shape)\n",
    "#     img = img[tf.newaxis, :]\n",
    "#     img = hub_model(tf.constant(img), tf.constant(style_image))[0]\n",
    "#     img = tensor_to_image(stylized_image_)\n",
    "#     img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    label = tf.one_hot(label, 2, dtype=tf.float32)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "b1a4e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_content(img):\n",
    "    max_dim = 512\n",
    "#     img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
    "    long_dim = max(shape)\n",
    "    scale = max_dim / long_dim\n",
    "\n",
    "    new_shape = tf.cast(shape * scale, tf.int32)\n",
    "\n",
    "    img = tf.image.resize(img, new_shape)\n",
    "    img = img[tf.newaxis, :]\n",
    "    \n",
    "    ######### newly added\n",
    "    image = hub_model(tf.constant(img), tf.constant(style_image))[0]\n",
    "    image = tensor_to_image(image)\n",
    "    print(image)\n",
    "    image = image.resize((96,96))\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    print('shape', image.shape)\n",
    "    \n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    print('shape2', image.shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8f444358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sample(sample):\n",
    "    image, label = sample['image'], sample['label'] \n",
    "#     image = preprocess_content(image)\n",
    "#     image = hub_model(tf.constant(image), tf.constant(style_image))[0]\n",
    "#     image = tensor_to_image(stylized_image_)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    label = tf.one_hot(label, 2, dtype=tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "2b4e0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train = list(pcam['train'])[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "2ae6c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_content(list_train[0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "901f29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img = [list_train[i]['image'] for i in range(len(list_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ce40871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label = [list_train[i]['label'] for i in range(len(list_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "4e3b44e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF6BB081F0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF54FB2820>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF6BB08B50>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF6BB08B50>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840CE6D0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF91421EE0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF91421EE0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF6BB08B50>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF91421EE0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF91421EE0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE006E760>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE006E040>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840D82E0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE006ECA0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE006ECA0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840D82E0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840D82E0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE006ECA0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE0062160>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840D82E0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840D82E0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840D82E0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE00624C0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE0062160>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840D82E0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE0062160>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD5A77CDF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840D82E0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840D82E0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840CED30>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE0062160>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840CED30>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840CED30>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE006E040>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE0062160>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE006E040>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF1000F850>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840D82E0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF8195BBE0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE006EAF0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF8195B250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF840B01F0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF8195B160>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF94290250>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD58ADBC70>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "list_img_convert = []\n",
    "for i, img in enumerate(list_img):\n",
    "#     print(preprocess_content(img))\n",
    "    list_img_convert.append(preprocess_content(img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "79830721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(96, 96, 3), dtype=float32, numpy=\n",
       "array([[[104., 137., 190.],\n",
       "        [100., 147., 193.],\n",
       "        [111., 149., 202.],\n",
       "        ...,\n",
       "        [123., 158., 194.],\n",
       "        [134., 166., 203.],\n",
       "        [135., 173., 220.]],\n",
       "\n",
       "       [[ 76., 124., 180.],\n",
       "        [110., 160., 198.],\n",
       "        [114., 146., 209.],\n",
       "        ...,\n",
       "        [128., 161., 217.],\n",
       "        [138., 153., 206.],\n",
       "        [131., 150., 212.]],\n",
       "\n",
       "       [[112., 133., 162.],\n",
       "        [127., 148., 185.],\n",
       "        [129., 156., 186.],\n",
       "        ...,\n",
       "        [130., 145., 187.],\n",
       "        [119., 128., 167.],\n",
       "        [110., 120., 168.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 85., 104., 119.],\n",
       "        [ 74.,  98., 132.],\n",
       "        [ 87., 106., 155.],\n",
       "        ...,\n",
       "        [203., 197., 110.],\n",
       "        [177., 178., 118.],\n",
       "        [181., 197., 159.]],\n",
       "\n",
       "       [[103., 128., 148.],\n",
       "        [ 96., 117., 121.],\n",
       "        [126., 140., 152.],\n",
       "        ...,\n",
       "        [175., 179., 118.],\n",
       "        [157., 179., 169.],\n",
       "        [120., 154., 178.]],\n",
       "\n",
       "       [[119., 129., 169.],\n",
       "        [142., 141., 154.],\n",
       "        [120., 119., 162.],\n",
       "        ...,\n",
       "        [142., 157., 177.],\n",
       "        [133., 157., 195.],\n",
       "        [129., 152., 200.]]], dtype=float32)>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_img_convert[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "682a713b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_img_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "bedfc8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label_convert = []\n",
    "for i, label in enumerate(list_label):\n",
    "    try:\n",
    "        list_label_convert.append(tf.one_hot(int(label), 2, dtype=tf.float32))\n",
    "    except TypeError:\n",
    "        list_label_convert.append(list_label[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "eea12b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_label_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "be5c05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transformed = tf.data.Dataset.from_tensor_slices((list_img_convert, list_label_convert))\n",
    "train_pipeline = dataset_transformed.shuffle(1024).repeat().batch(64).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "166437e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test = list(pcam['test'])[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "f6d91e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = [list_test[i]['image'] for i in range(len(list_test))]\n",
    "test_label = [list_test[i]['label'] for i in range(len(list_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "ce4659da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD8A5931F0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCDE0062490>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD8A5937C0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD8A5937C0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD8A5937C0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD8A5931F0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553790>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553F40>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553790>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553FD0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF880>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553FD0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553790>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553FD0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553FD0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FFEE0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD8A5937C0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF855534F0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD8A5937C0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCD8A5937C0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553FD0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553FD0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553FD0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF85553FD0>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF7060E070>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF100>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF100>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF100>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF915FF910>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF7060E070>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF7060EC10>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF7060E070>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF7060EC10>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF7060EC40>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF7060E070>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF7060E070>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n",
      "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FCF7060EC10>\n",
      "shape (96, 96, 3)\n",
      "shape2 (96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "test_img_convert = []\n",
    "for i, img in enumerate(test_img):\n",
    "    test_img_convert.append(preprocess_content(img))\n",
    "test_label_convert = []\n",
    "for i, label in enumerate(test_label):\n",
    "    try:\n",
    "        test_label_convert.append(tf.one_hot(int(label), 2, dtype=tf.float32))\n",
    "    except TypeError:\n",
    "        test_label_convert.append(list_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "45f06cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = tf.data.Dataset.from_tensor_slices((test_img_convert, test_label_convert))\n",
    "validation_pipeline = dataset_transformed.shuffle(1024).repeat().batch(64).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "36182932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4096/4096 - 1589s - loss: nan - accuracy: 0.5700 - val_loss: nan - val_accuracy: 0.5702\n",
      "Epoch 2/5\n",
      "4096/4096 - 3366s - loss: nan - accuracy: 0.5700 - val_loss: nan - val_accuracy: 0.5700\n",
      "Epoch 3/5\n",
      "4096/4096 - 1724s - loss: nan - accuracy: 0.5700 - val_loss: nan - val_accuracy: 0.5701\n",
      "Epoch 4/5\n",
      "4096/4096 - 1671s - loss: nan - accuracy: 0.5700 - val_loss: nan - val_accuracy: 0.5703\n",
      "Epoch 5/5\n",
      "4096/4096 - 7056s - loss: nan - accuracy: 0.5700 - val_loss: nan - val_accuracy: 0.5699\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_pipeline,\n",
    "                 validation_data=validation_pipeline,\n",
    "                 verbose=2, epochs=5, steps_per_epoch=4096, validation_steps=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06eb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba513c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "15477a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import glob\n",
    "import functools\n",
    "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
    "style_images = glob.glob(\"/Users/melody.zhao/Desktop/CS153-Computer-Vision/style_transfer_imgs/*\")\n",
    "style_image = load_img(style_images[2])\n",
    "\n",
    "def dataset_maker(image, label):\n",
    "#     image, label = dataset_obj[0],dataset_obj[1]\n",
    "#     image, label = image[\"args_0:0\"], label[\"args_1:0\"]\n",
    "#     image = preprocess_content(image)\n",
    "    print(tf.convert_to_tensor(image))\n",
    "    print(label)\n",
    "#     print(tf.constant(image))\n",
    "    image = hub_model(tf.constant(image), tf.constant(style_image))[0]\n",
    "    print('here2')\n",
    "    print(image)\n",
    "    image = tensor_to_image(image)\n",
    "#     image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    label = tf.one_hot(label, 2, dtype=tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "71d7ca4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c265e9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_img_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b7ba2bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512, 512, 3), dtype=float32, numpy=\n",
       "array([[[[0.9686275 , 0.8078432 , 0.8705883 ],\n",
       "         [0.9686275 , 0.8078432 , 0.8705883 ],\n",
       "         [0.9686275 , 0.8078432 , 0.8705883 ],\n",
       "         ...,\n",
       "         [0.9803922 , 0.8196079 , 0.89019614],\n",
       "         [0.9803922 , 0.8196079 , 0.89019614],\n",
       "         [0.9803922 , 0.8196079 , 0.89019614]],\n",
       "\n",
       "        [[0.9686275 , 0.8078432 , 0.8705883 ],\n",
       "         [0.9686275 , 0.8078432 , 0.8705883 ],\n",
       "         [0.9686275 , 0.8078432 , 0.8705883 ],\n",
       "         ...,\n",
       "         [0.9803922 , 0.8196079 , 0.89019614],\n",
       "         [0.9803922 , 0.8196079 , 0.89019614],\n",
       "         [0.9803922 , 0.8196079 , 0.89019614]],\n",
       "\n",
       "        [[0.9686275 , 0.8078432 , 0.8705883 ],\n",
       "         [0.9686275 , 0.8078432 , 0.8705883 ],\n",
       "         [0.9686275 , 0.8078432 , 0.8705883 ],\n",
       "         ...,\n",
       "         [0.9803922 , 0.8196079 , 0.89019614],\n",
       "         [0.9803922 , 0.8196079 , 0.89019614],\n",
       "         [0.9803922 , 0.8196079 , 0.89019614]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7607844 , 0.6666667 , 0.7294118 ],\n",
       "         [0.7607844 , 0.6666667 , 0.7294118 ],\n",
       "         [0.7607844 , 0.6666667 , 0.7294118 ],\n",
       "         ...,\n",
       "         [0.8705883 , 0.8078432 , 0.85098046],\n",
       "         [0.8705883 , 0.8078432 , 0.85098046],\n",
       "         [0.8705883 , 0.8078432 , 0.85098046]],\n",
       "\n",
       "        [[0.7607844 , 0.6666667 , 0.7294118 ],\n",
       "         [0.7607844 , 0.6666667 , 0.7294118 ],\n",
       "         [0.7607844 , 0.6666667 , 0.7294118 ],\n",
       "         ...,\n",
       "         [0.8705883 , 0.8078432 , 0.85098046],\n",
       "         [0.8705883 , 0.8078432 , 0.85098046],\n",
       "         [0.8705883 , 0.8078432 , 0.85098046]],\n",
       "\n",
       "        [[0.7607844 , 0.6666667 , 0.7294118 ],\n",
       "         [0.7607844 , 0.6666667 , 0.7294118 ],\n",
       "         [0.7607844 , 0.6666667 , 0.7294118 ],\n",
       "         ...,\n",
       "         [0.8705883 , 0.8078432 , 0.85098046],\n",
       "         [0.8705883 , 0.8078432 , 0.85098046],\n",
       "         [0.8705883 , 0.8078432 , 0.85098046]]]], dtype=float32)>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(list_img_convert[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c48e1f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((1, 512, 512, 3), ()), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((list(list_img_convert), list_label))\n",
    "print(dataset)\n",
    "# dataset = dataset.map(dataset_maker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3460f216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.9686275  0.8078432  0.8705883 ]\n",
      "   [0.9686275  0.8078432  0.8705883 ]\n",
      "   [0.9686275  0.8078432  0.8705883 ]\n",
      "   ...\n",
      "   [0.9803922  0.8196079  0.89019614]\n",
      "   [0.9803922  0.8196079  0.89019614]\n",
      "   [0.9803922  0.8196079  0.89019614]]\n",
      "\n",
      "  [[0.9686275  0.8078432  0.8705883 ]\n",
      "   [0.9686275  0.8078432  0.8705883 ]\n",
      "   [0.9686275  0.8078432  0.8705883 ]\n",
      "   ...\n",
      "   [0.9803922  0.8196079  0.89019614]\n",
      "   [0.9803922  0.8196079  0.89019614]\n",
      "   [0.9803922  0.8196079  0.89019614]]\n",
      "\n",
      "  [[0.9686275  0.8078432  0.8705883 ]\n",
      "   [0.9686275  0.8078432  0.8705883 ]\n",
      "   [0.9686275  0.8078432  0.8705883 ]\n",
      "   ...\n",
      "   [0.9803922  0.8196079  0.89019614]\n",
      "   [0.9803922  0.8196079  0.89019614]\n",
      "   [0.9803922  0.8196079  0.89019614]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.7607844  0.6666667  0.7294118 ]\n",
      "   [0.7607844  0.6666667  0.7294118 ]\n",
      "   [0.7607844  0.6666667  0.7294118 ]\n",
      "   ...\n",
      "   [0.8705883  0.8078432  0.85098046]\n",
      "   [0.8705883  0.8078432  0.85098046]\n",
      "   [0.8705883  0.8078432  0.85098046]]\n",
      "\n",
      "  [[0.7607844  0.6666667  0.7294118 ]\n",
      "   [0.7607844  0.6666667  0.7294118 ]\n",
      "   [0.7607844  0.6666667  0.7294118 ]\n",
      "   ...\n",
      "   [0.8705883  0.8078432  0.85098046]\n",
      "   [0.8705883  0.8078432  0.85098046]\n",
      "   [0.8705883  0.8078432  0.85098046]]\n",
      "\n",
      "  [[0.7607844  0.6666667  0.7294118 ]\n",
      "   [0.7607844  0.6666667  0.7294118 ]\n",
      "   [0.7607844  0.6666667  0.7294118 ]\n",
      "   ...\n",
      "   [0.8705883  0.8078432  0.85098046]\n",
      "   [0.8705883  0.8078432  0.85098046]\n",
      "   [0.8705883  0.8078432  0.85098046]]]], shape=(1, 512, 512, 3), dtype=float32)\n",
      "----\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for img, label in dataset:\n",
    "    print(img)\n",
    "    print('----')\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "352a8676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_image(tensor):\n",
    "  tensor = tensor*255\n",
    "  tensor = np.array(tensor, dtype=np.uint8)\n",
    "  if np.ndim(tensor)>3:\n",
    "    assert tensor.shape[0] == 1\n",
    "    tensor = tensor[0]\n",
    "  return PIL.Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "93ce985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"args_0:0\", shape=(1, 512, 512, 3), dtype=float32)\n",
      "Tensor(\"args_1:0\", shape=(), dtype=int64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /var/folders/sc/4krr0g1j1fsg07slzqv1h0980000gr/T/ipykernel_77165/1070703169.py:14 dataset_maker  *\n        image = hub_model(tf.constant(image), tf.constant(style_image))[0]\n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:271 constant  **\n        \n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:288 _constant_impl\n        \n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:457 make_tensor_proto\n        \n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:334 _AssertCompatible\n        \n\n    TypeError: Expected any non-tensor type, got a tensor instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sc/4krr0g1j1fsg07slzqv1h0980000gr/T/ipykernel_77165/1622626842.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_maker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /var/folders/sc/4krr0g1j1fsg07slzqv1h0980000gr/T/ipykernel_77165/1070703169.py:14 dataset_maker  *\n        image = hub_model(tf.constant(image), tf.constant(style_image))[0]\n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:271 constant  **\n        \n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:288 _constant_impl\n        \n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:457 make_tensor_proto\n        \n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:334 _AssertCompatible\n        \n\n    TypeError: Expected any non-tensor type, got a tensor instead.\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(dataset_maker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4b57603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 1, 512, 512, 3), (None, 2)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shuffle(1024).repeat().batch(64).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401a4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "02c8758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = map(convert_sample, list_train)\n",
    "\n",
    "\n",
    "# print(list(pcam['train'])map(convert_sample))\n",
    "# print(pcam['train'])\n",
    "# print(tf.map_fn(convert_sample, pcam['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6921383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ParallelMapDataset shapes: ((96, 96, 3), (2,)), types: (tf.float32, tf.float32)>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'map' object has no attribute 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sc/4krr0g1j1fsg07slzqv1h0980000gr/T/ipykernel_74745/1910921325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m print(pcam['validation'].map(convert_sample,\n\u001b[1;32m      2\u001b[0m                                         num_parallel_calls=8))\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'map' object has no attribute 'shuffle'"
     ]
    }
   ],
   "source": [
    "print(pcam['validation'].map(convert_sample,\n",
    "                                        num_parallel_calls=8))\n",
    "output.shuffle(1024).repeat().batch(64).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30f82816",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    /var/folders/sc/4krr0g1j1fsg07slzqv1h0980000gr/T/ipykernel_74745/2708019344.py:3 convert_sample  *\n        image = preprocess_content(image)\n    /var/folders/sc/4krr0g1j1fsg07slzqv1h0980000gr/T/ipykernel_74745/501126989.py:8 preprocess_content  *\n        long_dim = max(shape)\n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:520 __iter__  **\n        self._disallow_iteration()\n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:513 _disallow_iteration\n        self._disallow_when_autograph_enabled(\"iterating over `tf.Tensor`\")\n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:489 _disallow_when_autograph_enabled\n        raise errors.OperatorNotAllowedInGraphError(\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sc/4krr0g1j1fsg07slzqv1h0980000gr/T/ipykernel_74745/550255693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# prefetch 2 batches such that we can get batches during training on the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m train_pipeline = pcam['train'].map(convert_sample,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                    num_parallel_calls=8).shuffle(1024).repeat().batch(64).prefetch(2)\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# train_pipeline = tf.map_fn(convert_sample, pcam['train']).shuffle(1024).repeat().batch(64).prefetch(2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1861\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m       return ParallelMapDataset(\n\u001b[0m\u001b[1;32m   1864\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m           \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   5018\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5019\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5020\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   5021\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5022\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4216\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4218\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4219\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4220\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3148\u001b[0m          \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m     \"\"\"\n\u001b[0;32m-> 3150\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   3151\u001b[0m         *args, **kwargs)\n\u001b[1;32m   3152\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3114\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4193\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   4194\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4195\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4196\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4197\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4123\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4124\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4125\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4126\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4127\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    /var/folders/sc/4krr0g1j1fsg07slzqv1h0980000gr/T/ipykernel_74745/2708019344.py:3 convert_sample  *\n        image = preprocess_content(image)\n    /var/folders/sc/4krr0g1j1fsg07slzqv1h0980000gr/T/ipykernel_74745/501126989.py:8 preprocess_content  *\n        long_dim = max(shape)\n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:520 __iter__  **\n        self._disallow_iteration()\n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:513 _disallow_iteration\n        self._disallow_when_autograph_enabled(\"iterating over `tf.Tensor`\")\n    /Users/melody.zhao/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:489 _disallow_when_autograph_enabled\n        raise errors.OperatorNotAllowedInGraphError(\n\n    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n"
     ]
    }
   ],
   "source": [
    "# shuffle the training data with a shuffle buffer \n",
    "# batches of 64 patches for training and 128 for validation\n",
    "# prefetch 2 batches such that we can get batches during training on the GPU\n",
    "\n",
    "train_pipeline = list(pcam['train']).map(convert_sample,\n",
    "                                   num_parallel_calls=8).shuffle(1024).repeat().batch(64).prefetch(2)\n",
    "# train_pipeline = tf.map_fn(convert_sample, pcam['train']).shuffle(1024).repeat().batch(64).prefetch(2)\n",
    "valid_pipeline = pcam['validation'].map(convert_sample,\n",
    "                                        num_parallel_calls=8).repeat().batch(128).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ddf3dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 14:53:17.051142: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4096 - 1249s - loss: 0.4464 - accuracy: 0.7818 - val_loss: 0.3864 - val_accuracy: 0.8252\n",
      "Epoch 2/5\n",
      "4096/4096 - 1250s - loss: 0.3151 - accuracy: 0.8676 - val_loss: 0.3782 - val_accuracy: 0.8277\n",
      "Epoch 3/5\n",
      "4096/4096 - 1236s - loss: 0.2652 - accuracy: 0.8919 - val_loss: 0.3690 - val_accuracy: 0.8355\n",
      "Epoch 4/5\n",
      "4096/4096 - 1187s - loss: 0.2314 - accuracy: 0.9085 - val_loss: 0.3809 - val_accuracy: 0.8322\n",
      "Epoch 5/5\n",
      "4096/4096 - 1198s - loss: 0.2072 - accuracy: 0.9190 - val_loss: 0.3459 - val_accuracy: 0.8548\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_pipeline,\n",
    "                 validation_data=valid_pipeline,\n",
    "                 verbose=2, epochs=5, steps_per_epoch=4096, validation_steps=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cae2964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy is 0.8135\n"
     ]
    }
   ],
   "source": [
    "test_pipeline = pcam['test'].map(convert_sample, num_parallel_calls=8).batch(128).prefetch(2)\n",
    "print(\"Test set accuracy is {0:.4f}\".format(model.evaluate(test_pipeline, steps=128, verbose=0)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "021ab023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 16:52:55.329975: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./patchcamelyon.hf5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./patchcamelyon.hf5/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./patchcamelyon.hf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda297ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

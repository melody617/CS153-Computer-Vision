Unloaded dependency: anaconda3/2020.11

CommandNotFoundError: Your shell has not been properly configured to use 'conda deactivate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


Unloading the anaconda2 module (if loaded)...
Loaded dependency: anaconda3/2020.11
AI/Version: anaconda3.2020.11
-----------------------------

Description
-----------
The modulefile AI/anaconda3.2020.11 provides a unified, rich, anaconda3 based
environment for Artificial Intelligence(AI)/Machine Learning(ML)/Big Data(BD)
on top of based on Python 3.

Module contents
---------------
Several popular AI/ML/BD packages are included in this environment, such as:
    tensorflow-gpu, theano, keras-gpu, pytorch, opencv, pandas, scikit-learn,
scikit-image etc.

To check the full list of available packages in this environment, first
activate it and then run the command
    conda list

Main packages included in this module:
* astropy 4.2
* blas 1.0
* bokeh 2.2.3
* cudatoolkit 10.0.130
* cudnn 7.6.5
* h5py 2.8.0
* hdf5 1.10.2
* ipython 7.19.0
* jupyter 1.0.0
* jupyterlab 2.2.6
* keras-gpu 2.3.1
* matplotlib 3.3.2
* mkl 2019.4
* nccl 1.3.5
* networkx 2.5
* ninja 1.10.2
* nltk 3.5
* notebook 6.1.6
* numba 0.51.2
* numpy 1.17.0
* opencv 3.4.2
* pandas 1.2.0
* pillow 8.1.0
* pip 20.3.3
* python 3.8.5
* pytorch 1.5.0
* scikit-learn 0.23.2
* scipy 1.5.2
* seaborn 0.11.1
* tensorboard 1.15.0
* tensorflow-gpu 1.15.0
* theano 1.0.4

If you need to further customize this environment (e.g., install additional
packages, or upgrade a particular package),
you should first clone this environment as follows:
    conda create --prefix <path to a dir in which you can write> --clone
$AI_ENV
Then activate the newly spawned environment and proceed with your
customization.

To get further help with conda usage, you can try one of the following:
    conda -h
    conda <command> -h

Activate the module
-------------------
Before activating, make sure you are on a GPU node of Bridges2 if you wish to
use the components built to run on GPUs.
To activate the environment, run the following commands:
    # module load AI/anaconda3.2020.11
    source activate $AI_ENV
        # OR
    conda activate $AI_ENV # This might require you to run "conda init" first.

2021-11-29 03:03:39.178946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-29 03:03:39.178988: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-11-29 03:04:30.654224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-11-29 03:04:30.654686: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory
2021-11-29 03:04:30.654938: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory
2021-11-29 03:04:30.655129: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory
2021-11-29 03:04:30.655927: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory
2021-11-29 03:04:30.656139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory
2021-11-29 03:04:30.656340: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory
2021-11-29 03:04:30.656524: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2021-11-29 03:04:30.678195: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-11-29 03:04:30.727608: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
tfds.core.DatasetInfo(
    name='patch_camelyon',
    full_name='patch_camelyon/2.0.0',
    description="""
    The PatchCamelyon benchmark is a new and challenging image classification
    dataset. It consists of 327.680 color images (96 x 96px) extracted from
    histopathologic scans of lymph node sections. Each image is annoted with a
    binary label indicating presence of metastatic tissue. PCam provides a new
    benchmark for machine learning models: bigger than CIFAR10, smaller than
    Imagenet, trainable on a single GPU.
    """,
    homepage='https://patchcamelyon.grand-challenge.org/',
    data_path='./tensorflow_datasets/patch_camelyon/2.0.0',
    download_size=7.48 GiB,
    dataset_size=7.06 GiB,
    features=FeaturesDict({
        'id': Text(shape=(), dtype=tf.string),
        'image': Image(shape=(96, 96, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    }),
    supervised_keys=('image', 'label'),
    disable_shuffling=False,
    splits={
        'test': <SplitInfo num_examples=32768, num_shards=8>,
        'train': <SplitInfo num_examples=262144, num_shards=64>,
        'validation': <SplitInfo num_examples=32768, num_shards=8>,
    },
    citation="""@misc{b_s_veeling_j_linmans_j_winkens_t_cohen_2018_2546921,
      author       = {B. S. Veeling, J. Linmans, J. Winkens, T. Cohen, M. Welling},
      title        = {Rotation Equivariant CNNs for Digital Pathology},
      month        = sep,
      year         = 2018,
      doi          = {10.1007/978-3-030-00934-2_24},
      url          = {https://doi.org/10.1007/978-3-030-00934-2_24}
    }""",
)
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 96, 96, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 94, 94, 16)        448       
                                                                 
 conv2d_1 (Conv2D)           (None, 92, 92, 16)        2320      
                                                                 
 max_pooling2d (MaxPooling2D  (None, 46, 46, 16)       0         
 )                                                               
                                                                 
 conv2d_2 (Conv2D)           (None, 44, 44, 32)        4640      
                                                                 
 conv2d_3 (Conv2D)           (None, 42, 42, 32)        9248      
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 21, 21, 32)       0         
 2D)                                                             
                                                                 
 conv2d_4 (Conv2D)           (None, 19, 19, 64)        18496     
                                                                 
 conv2d_5 (Conv2D)           (None, 17, 17, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 4096)              0         
                                                                 
 dense (Dense)               (None, 256)               1048832   
                                                                 
 dropout (Dropout)           (None, 256)               0         
                                                                 
 dense_1 (Dense)             (None, 128)               32896     
                                                                 
 dropout_1 (Dropout)         (None, 128)               0         
                                                                 
 dense_2 (Dense)             (None, 2)                 258       
                                                                 
=================================================================
Total params: 1,154,066
Trainable params: 1,154,066
Non-trainable params: 0
_________________________________________________________________
generate training material...
generate validation material...
begining training...
Epoch 1/10
2048/2048 - 375s - loss: 0.5045 - accuracy: 0.7587 - val_loss: 0.4294 - val_accuracy: 0.8048 - 375s/epoch - 183ms/step
Epoch 2/10
2048/2048 - 368s - loss: 0.4078 - accuracy: 0.8234 - val_loss: 0.4283 - val_accuracy: 0.8049 - 368s/epoch - 180ms/step
Epoch 3/10
2048/2048 - 356s - loss: 0.3884 - accuracy: 0.8344 - val_loss: 0.4240 - val_accuracy: 0.8096 - 356s/epoch - 174ms/step
Epoch 4/10
2048/2048 - 367s - loss: 0.3643 - accuracy: 0.8458 - val_loss: 0.4588 - val_accuracy: 0.8123 - 367s/epoch - 179ms/step
Epoch 5/10
2048/2048 - 367s - loss: 0.3588 - accuracy: 0.8498 - val_loss: 0.4188 - val_accuracy: 0.7956 - 367s/epoch - 179ms/step
Epoch 6/10
2048/2048 - 369s - loss: 0.3440 - accuracy: 0.8582 - val_loss: 0.4344 - val_accuracy: 0.8092 - 369s/epoch - 180ms/step
Epoch 7/10
2048/2048 - 367s - loss: 0.3431 - accuracy: 0.8580 - val_loss: 0.3944 - val_accuracy: 0.8235 - 367s/epoch - 179ms/step
Epoch 8/10
2048/2048 - 365s - loss: 0.3338 - accuracy: 0.8638 - val_loss: 0.4040 - val_accuracy: 0.8222 - 365s/epoch - 178ms/step
Epoch 9/10
2048/2048 - 365s - loss: 0.3359 - accuracy: 0.8639 - val_loss: 0.3846 - val_accuracy: 0.8161 - 365s/epoch - 178ms/step
Epoch 10/10
2048/2048 - 367s - loss: 0.3293 - accuracy: 0.8674 - val_loss: 0.4417 - val_accuracy: 0.7863 - 367s/epoch - 179ms/step
generate test material...
Test set accuracy is 0.7404
2021-11-29 04:14:57.884452: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
/ocean/projects/cis210064p/mezhao/cs153xsede/env/lib/python3.7/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(SGD, self).__init__(name, **kwargs)
